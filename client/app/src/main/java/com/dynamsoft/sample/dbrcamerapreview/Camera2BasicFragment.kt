/*
 * Copyright 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *       http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.dynamsoft.sample.dbrcamerapreview

import android.Manifest
import android.app.Activity
import android.app.AlertDialog
import android.app.Dialog
import android.content.Context
import android.content.Intent
import android.content.pm.PackageManager
import android.content.res.Configuration
import android.graphics.*
import android.hardware.camera2.*
import android.hardware.camera2.CameraCaptureSession.CaptureCallback
import android.hardware.camera2.params.MeteringRectangle
import android.media.ImageReader
import android.media.ImageReader.OnImageAvailableListener
import android.os.*
import androidx.annotation.RequiresApi
import androidx.core.app.ActivityCompat.OnRequestPermissionsResultCallback
import androidx.fragment.app.DialogFragment
import androidx.fragment.app.Fragment
import androidx.core.content.ContextCompat
import android.util.Log
import android.util.Size
import android.util.SparseIntArray
import android.view.*
import android.view.GestureDetector.SimpleOnGestureListener
import android.view.TextureView.SurfaceTextureListener
import android.widget.TextView
import android.widget.Toast
import com.dynamsoft.dbr.EnumImagePixelFormat
import com.dynamsoft.dbr.LocalizationResult
import com.dynamsoft.dbr.TextResult
import com.dynamsoft.sample.dbrcamerapreview.util.CameraUtil.convertFrameRegionToViewRegion
import com.dynamsoft.sample.dbrcamerapreview.util.CameraUtil.getOrientationDisplayOffset
import java.io.ByteArrayOutputStream
import java.io.File
import java.io.FileOutputStream
import java.io.IOException
import java.util.*
import java.util.concurrent.Semaphore
import java.util.concurrent.TimeUnit
import kotlin.math.max
import kotlin.math.min

class Camera2BasicFragment : Fragment(), OnRequestPermissionsResultCallback {
    /**
     * A [Semaphore] to prevent the app from exiting before closing the camera.
     */
    private val mCameraOpenCloseLock = Semaphore(1)

    /**
     * This a callback object for the [ImageReader]. "onImageAvailable" will be called when a
     * still image is ready to be saved.
     */
    private lateinit var mHandler: Handler

    /**
     * A [CameraCaptureSession.CaptureCallback] that handles events related to JPEG capture.
     */
    private val mCaptureCallback: CaptureCallback? = null

    private lateinit var mResult: TextView

    private var w = 0 // width of camera
    private var h = 0 // height of camera
    var mZoomState = 0 // 0-original, 1-zoom in, 2-zoom hold
    private var mMainActivity: MainActivity? = null

    /**
     * ID of the current [CameraDevice].
     */
    private var mCameraId: String? = null

    /**
     * An [AutoFitTextureView] for camera preview.
     */
    private lateinit var mTextureView: AutoFitTextureView

    /**
     * A [CameraCaptureSession] for camera preview.
     */
    private var mCaptureSession: CameraCaptureSession? = null

    /**
     * A reference to the opened [CameraDevice].
     */
    private var mCameraDevice: CameraDevice? = null

    /**
     * The [Size] of camera preview.
     */
    private var mPreviewSize: Size? = null

    /**
     * An additional thread for running tasks that shouldn't block the UI.
     */
    private var mBackgroundThread: HandlerThread? = null
    private var mBackgroundThread2: HandlerThread? = null

    /**
     * A [Handler] for running tasks in the background.
     */
    private var mBackgroundHandler: Handler? = null
    private var mBackgroundHandler2: Handler? = null

    /**
     * An [ImageReader] that handles still image capture.
     */
    private var mImageReader: ImageReader? = null
    private var outputPreviewSize: Size? = null

    /**
     * [CaptureRequest.Builder] for the camera preview
     */
    private var mPreviewRequestBuilder: CaptureRequest.Builder? = null

    /**
     * [CaptureRequest] generated by [.mPreviewRequestBuilder]
     */
    private var mPreviewRequest: CaptureRequest? = null

    /**
     * Whether the current camera device supports Flash or not.
     */
    private var mFlashSupported = false

    /**
     * Orientation of the camera sensor
     */
    private var mSensorOrientation = 0
    private var mQrView: QRCodeView? = null
    private lateinit var mQrCropRect: Rect
    private lateinit var mCameraCharacteristics: CameraCharacteristics
    private val mOnImageAvailableListener = OnImageAvailableListener { reader ->
        if (reader != null) {
            val mImage = reader.acquireLatestImage()
            if (mImage != null) {
                val buffer = mImage.planes[0].buffer
                val nRowStride = mImage.planes[0].rowStride
                val nPixelStride = mImage.planes[0].pixelStride
                if (mBackgroundHandler2 != null && !bDecoding) {
                    bDecoding = true
                    val bytes = ByteArray(buffer.remaining())
                    buffer[bytes]
                    val imageData = ImageData(bytes, reader.width, reader.height, nRowStride * nPixelStride)
                    val message = Message()
                    message.what = 0x101
                    message.obj = imageData
                    mBackgroundHandler2!!.sendMessage(message)
                }
                mImage.close()
            }
        }
    }

    /**
     * [CameraDevice.StateCallback] is called when [CameraDevice] changes its state.
     */
    private val mStateCallback: CameraDevice.StateCallback = object : CameraDevice.StateCallback() {
        override fun onOpened(cameraDevice: CameraDevice) {
            // This method is called when the camera is opened.  We start camera preview here.
            mCameraOpenCloseLock.release()
            mCameraDevice = cameraDevice
            createCameraPreviewSession()
        }

        override fun onDisconnected(cameraDevice: CameraDevice) {
            mCameraOpenCloseLock.release()
            cameraDevice.close()
            mCameraDevice = null
        }

        override fun onError(cameraDevice: CameraDevice, error: Int) {
            mCameraOpenCloseLock.release()
            cameraDevice.close()
            mCameraDevice = null
            val activity: Activity? = activity
            activity?.finish()
        }
    }

    /**
     * [TextureView.SurfaceTextureListener] handles several lifecycle events on a
     * [TextureView].
     */
    private val mSurfaceTextureListener: SurfaceTextureListener = object : SurfaceTextureListener {
        override fun onSurfaceTextureAvailable(texture: SurfaceTexture, width: Int, height: Int) {
            openCamera(width, height)
        }

        override fun onSurfaceTextureSizeChanged(texture: SurfaceTexture, width: Int, height: Int) {
            configureTransform(width, height)
        }

        override fun onSurfaceTextureDestroyed(texture: SurfaceTexture): Boolean {
            return true
        }

        override fun onSurfaceTextureUpdated(texture: SurfaceTexture) {}
    }

    /**
     * Shows a [Toast] on the UI thread.
     *
     * @param text The message to show
     */
    private fun showToast(text: String) {
        val activity: Activity? = activity
        activity?.runOnUiThread { Toast.makeText(activity, text, Toast.LENGTH_SHORT).show() }
    }

    override fun onCreateView(inflater: LayoutInflater, container: ViewGroup?,
                              savedInstanceState: Bundle?): View? {
        mMainActivity = activity as MainActivity?
        return inflater.inflate(R.layout.fragment_camera2_basic, container, false)
    }

    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {
        mResult = view.findViewById(R.id.tv_result)
        mTextureView = view.findViewById(R.id.texture)
        mQrView = view.findViewById(R.id.qr_view)
        mHandler = MyHandler(mResult)
        //mQrView.setVisibility(View.INVISIBLE);
        mTextureView.setGestureListener(object : SimpleOnGestureListener() {
            override fun onSingleTapUp(e: MotionEvent): Boolean {
                return true
            }
        })
    }

    override fun onResume() {
        super.onResume()
        startBackgroundThread()

        // When the screen is turned off and turned back on, the SurfaceTexture is already
        // available, and "onSurfaceTextureAvailable" will not be called. In that case, we can open
        // a camera and start preview from here (otherwise, we wait until the surface is ready in
        // the SurfaceTextureListener).
        if (mTextureView.isAvailable) {
            openCamera(mTextureView.width, mTextureView.height)
        } else {
            mTextureView.surfaceTextureListener = mSurfaceTextureListener
        }
    }

    override fun onPause() {
        closeCamera()
        stopBackgroundThread()
        super.onPause()
    }

    private fun requestCameraPermission() {
        if (shouldShowRequestPermissionRationale(Manifest.permission.CAMERA)) {
            ConfirmationDialog().show(childFragmentManager, FRAGMENT_DIALOG)
        } else {
            requestPermissions(arrayOf(Manifest.permission.CAMERA), REQUEST_CAMERA_PERMISSION)
        }
    }

    override fun onRequestPermissionsResult(requestCode: Int, permissions: Array<String>, grantResults: IntArray) {
        if (requestCode == REQUEST_CAMERA_PERMISSION) {
            if (grantResults.size != 1 || grantResults[0] != PackageManager.PERMISSION_GRANTED) {
                ErrorDialog.newInstance(getString(R.string.request_permission))
                        .show(childFragmentManager, FRAGMENT_DIALOG)
            }
        } else {
            super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        }
    }

    private fun setUpCameraOutputs(width: Int, height: Int) {
        val activity: Activity = activity ?: let { Log.e(TAG, "Activity was NULL"); return }
        val manager = activity.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try {
            for (cameraId in manager.cameraIdList) {
                mCameraCharacteristics = manager.getCameraCharacteristics(cameraId)

                // We don't use a front facing camera in this sample.
                val facing = mCameraCharacteristics.get(CameraCharacteristics.LENS_FACING)
                if (facing != null && facing == CameraCharacteristics.LENS_FACING_FRONT) {
                    continue
                }
                val map = mCameraCharacteristics.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP) ?: continue

                // For video image captures, we use the suitable available size.
                val sizeList = map.getOutputSizes(ImageFormat.YUV_420_888)
                for (size in sizeList) {
                    if (size.width * size.height > 1000000) continue else {
                        outputPreviewSize = size
                        break
                    }
                }
                mImageReader = ImageReader.newInstance(outputPreviewSize!!.width, outputPreviewSize!!.height,
                        ImageFormat.YUV_420_888, 3)
                mImageReader!!.setOnImageAvailableListener(
                        mOnImageAvailableListener, null) // mBackgroundHandler2);

                // Find out if we need to swap dimension to get the preview size relative to sensor
                // coordinate.
                val displayRotation = activity.windowManager.defaultDisplay.rotation
                mSensorOrientation = mCameraCharacteristics.get(CameraCharacteristics.SENSOR_ORIENTATION)
                var swappedDimensions = false
                when (displayRotation) {
                    Surface.ROTATION_0, Surface.ROTATION_180 -> if (mSensorOrientation == 90 || mSensorOrientation == 270) {
                        swappedDimensions = true
                    }
                    Surface.ROTATION_90, Surface.ROTATION_270 -> if (mSensorOrientation == 0 || mSensorOrientation == 180) {
                        swappedDimensions = true
                    }
                    else -> Log.e(TAG, "Display rotation is invalid: $displayRotation")
                }
                val displaySize = Point()
                activity.windowManager.defaultDisplay.getSize(displaySize)
                var rotatedPreviewWidth = width
                var rotatedPreviewHeight = height
                var maxPreviewWidth = displaySize.x
                var maxPreviewHeight = displaySize.y
                if (swappedDimensions) {
                    rotatedPreviewWidth = height
                    rotatedPreviewHeight = width
                    maxPreviewWidth = displaySize.y
                    maxPreviewHeight = displaySize.x
                }
                if (maxPreviewWidth > MAX_PREVIEW_WIDTH) {
                    maxPreviewWidth = MAX_PREVIEW_WIDTH
                }
                if (maxPreviewHeight > MAX_PREVIEW_HEIGHT) {
                    maxPreviewHeight = MAX_PREVIEW_HEIGHT
                }

                // Danger, W.R.! Attempting to use too large a preview size could  exceed the camera
                // bus' bandwidth limitation, resulting in gorgeous previews but the storage of
                // garbage capture data.
                mPreviewSize = chooseOptimalSize(map.getOutputSizes(SurfaceTexture::class.java),
                        rotatedPreviewWidth, rotatedPreviewHeight, maxPreviewWidth,
                        maxPreviewHeight, outputPreviewSize)

                // We fit the aspect ratio of TextureView to the size of preview we picked.
                val orientation = resources.configuration.orientation
                if (orientation == Configuration.ORIENTATION_LANDSCAPE) {
                    mTextureView.setAspectRatio(
                            mPreviewSize!!.width, mPreviewSize!!.height)
                } else {
                    mTextureView.setAspectRatio(
                            mPreviewSize!!.height, mPreviewSize!!.width)
                }


                // Check if the flash is supported.
                val available = mCameraCharacteristics.get(CameraCharacteristics.FLASH_INFO_AVAILABLE)
                mFlashSupported = available ?: false
                mCameraId = cameraId
                checkFlashSupported()
                if (w == 0 || h == 0) {
                    w = mTextureView.width
                    h = mTextureView.height
                }
                //show the crop view
                var nQrViewW = w * 3 / 4
                var nQrViewH = h * 3 / 4
                if (nQrViewH > nQrViewW) nQrViewH = nQrViewW else nQrViewW = nQrViewH
                val boxLeft = (w - nQrViewW) / 2
                val boxTop = (h - nQrViewH) / 2
                if (boxLeft >= 0 && boxTop >= 0) {
                    mQrCropRect = Rect(boxLeft, boxTop, boxLeft + nQrViewW, boxTop + nQrViewH)
                    mQrView!!.resetBoxView(mQrCropRect.left, mQrCropRect.top, mQrCropRect.width(), mQrCropRect.height())
                }
                return
            }
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        } catch (e: NullPointerException) {
            // Currently an NPE is thrown when the Camera2API is used but not supported on the
            // device this code runs.
            ErrorDialog.newInstance(getString(R.string.camera_error))
                    .show(childFragmentManager, FRAGMENT_DIALOG)
        }
    }

    /**
     * Opens the camera specified by [Camera2BasicFragment.mCameraId].
     */
    private fun openCamera(width: Int, height: Int) {
        if (ContextCompat.checkSelfPermission(activity!!, Manifest.permission.CAMERA)
                != PackageManager.PERMISSION_GRANTED) {
            requestCameraPermission()
            return
        }
        setUpCameraOutputs(width, height)
        configureTransform(width, height)
        val activity: Activity? = activity
        val manager = activity!!.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try {
            if (!mCameraOpenCloseLock.tryAcquire(2500, TimeUnit.MILLISECONDS)) {
                throw RuntimeException("Time out waiting to lock camera opening.")
            }
            manager.openCamera(mCameraId!!, mStateCallback, mBackgroundHandler)
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        } catch (e: InterruptedException) {
            throw RuntimeException("Interrupted while trying to lock camera opening.", e)
        }
    }

    /**
     * Closes the current [CameraDevice].
     */
    private fun closeCamera() {
        try {
            mCameraOpenCloseLock.acquire()
            if (null != mCaptureSession) {
                mCaptureSession!!.close()
                mCaptureSession = null
            }
            if (null != mCameraDevice) {
                mCameraDevice!!.close()
                mCameraDevice = null
            }
            if (null != mImageReader) {
                mImageReader!!.close()
                mImageReader = null
            }
        } catch (e: InterruptedException) {
            throw RuntimeException("Interrupted while trying to lock camera closing.", e)
        } finally {
            mCameraOpenCloseLock.release()
        }
    }

    /**
     * Starts a background thread and its [Handler].
     */
    private fun startBackgroundThread() {
        mBackgroundThread = HandlerThread("CameraBackground")
        mBackgroundThread!!.start()
        mBackgroundHandler = Handler(mBackgroundThread!!.looper)
        mBackgroundThread2 = HandlerThread("CameraBK2")
        mBackgroundThread2!!.start()
        mBackgroundHandler2 = object : Handler(mBackgroundThread2!!.looper) {
            override fun handleMessage(msg: Message) {
                if (msg.obj == null) return
                val message = mHandler.obtainMessage()
                message.what = 0x02
                val imageData = msg.obj as ImageData
                try {
                    val results = mMainActivity!!.mainBarcodeReader!!.decodeBuffer(imageData.mBytes, imageData.mWidth, imageData.mHeight, imageData.mStride, EnumImagePixelFormat.IPF_NV21, "")
                    var bTempCropContains = false
                    if (mMainActivity!!.mainBarcodeReader!!.intermediateResults.isNotEmpty()) {
                        val intermediateResults = mMainActivity!!.mainBarcodeReader!!.intermediateResults
                        val localizationResults = intermediateResults[0].results as Array<*>
                        for (result in localizationResults) {
                            if (result is LocalizationResult) {
                                val points = result.resultPoints
                                var leftX: Int
                                var leftY: Int
                                var rightX: Int
                                var rightY: Int
                                leftX = points[0].x
                                rightX = leftX
                                leftY = points[0].y
                                rightY = leftY
                                for (pt in points) {
                                    if (pt.x < leftX) leftX = pt.x
                                    if (pt.y < leftY) leftY = pt.y
                                    if (pt.x > rightX) rightX = pt.x
                                    if (pt.y > rightY) rightY = pt.y
                                }
                                val frameRegion = Rect(leftX, leftY, rightX, rightY)
                                val frameSize = Rect(0, 0, outputPreviewSize!!.width, outputPreviewSize!!.height)
                                val viewRegion = convertFrameRegionToViewRegion(frameRegion, frameSize, getOrientationDisplayOffset(Objects.requireNonNull(activity)!!, mSensorOrientation), Size(mTextureView.width, mTextureView.height))
                                if (mQrCropRect.contains(viewRegion) || viewRegion.contains(mQrCropRect) || mQrCropRect.intersect(mQrCropRect)) {
                                    mZoomState = if (mQrCropRect.contains(viewRegion)) {
                                        1 //zoom in
                                    } else {
                                        2 //zoom hold
                                    }
                                    bTempCropContains = true
                                    break
                                }
                            }
                        }
                    }
                    if (!bTempCropContains) {
                        mZoomState = 0 //zoom original
                    }
                    if (results != null && results.isNotEmpty()) {
                        message.obj = parseResult(results)
                        onScan((message.obj as String).takeLast(10))
                    } else {
                        message.obj = ""
                    }
                    mHandler.sendMessage(message)
                } catch (e: Exception) {
                    e.printStackTrace()
                    Log.d("BarcodeReaderException", e.message)
                    message.obj = ""
                    mHandler.sendMessage(message)
                } finally {
                    bDecoding = false
                }
                super.handleMessage(msg)
            }
        }
    }

    private fun onScan(barcode: String) {
        if (barcode.all { it.isDigit() }) {
            val intent = Intent(mMainActivity, ScannedItemActivity::class.java).apply {
                putExtra("barcode", barcode)
            }
            startActivity(intent)
        }
    }

    /**
     * Stops the background thread and its [Handler].
     */
    private fun stopBackgroundThread() {
        mBackgroundThread!!.quitSafely()
        try {
            mBackgroundThread!!.join()
            mBackgroundThread = null
            mBackgroundHandler = null
        } catch (e: InterruptedException) {
            e.printStackTrace()
        }
        mBackgroundThread2!!.quitSafely()
        try {
            mBackgroundThread2!!.join()
            mBackgroundThread2 = null
            mBackgroundHandler2 = null
        } catch (e: InterruptedException) {
            e.printStackTrace()
        }
    }

    /**
     * Creates a new [CameraCaptureSession] for camera preview.
     */
    private fun createCameraPreviewSession() {
        try {
            val texture = mTextureView.surfaceTexture!!

            // We configure the size of default buffer to be the size of camera preview we want.
            texture.setDefaultBufferSize(mPreviewSize!!.width, mPreviewSize!!.height)

            // This is the output Surface we need to start preview.
            val surface = Surface(texture)

            // We set up a CaptureRequest.Builder with the output Surface.
            mPreviewRequestBuilder = mCameraDevice!!.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW)
            mPreviewRequestBuilder!!.addTarget(surface)
            mPreviewRequestBuilder!!.addTarget(mImageReader!!.surface)

            val boxWidth = min(mPreviewSize!!.width * 3 / 4, mPreviewSize!!.height * 3 / 4)
            mPreviewRequestBuilder!!.set(CaptureRequest.CONTROL_AF_REGIONS, arrayOf(
                    MeteringRectangle(
                            Point((mPreviewSize!!.width - boxWidth) / 2, (mPreviewSize!!.height - boxWidth) / 2),
                            Size(boxWidth, boxWidth), 1000)))

            mPreviewRequestBuilder!!.set(CaptureRequest.CONTROL_AE_REGIONS, arrayOf(
                    MeteringRectangle(
                            Point((mPreviewSize!!.width - boxWidth) / 2, (mPreviewSize!!.height - boxWidth) / 2),
                            Size(boxWidth, boxWidth), 1000)))

            // Here, we create a CameraCaptureSession for camera preview.
            mCameraDevice!!.createCaptureSession(listOf(surface, mImageReader!!.surface),
                    object : CameraCaptureSession.StateCallback() {
                        override fun onConfigured(cameraCaptureSession: CameraCaptureSession) {
                            // The camera is already closed
                            if (null == mCameraDevice) {
                                return
                            }

                            // When the session is ready, we start displaying the preview.
                            mCaptureSession = cameraCaptureSession
                            try {
                                // Finally, we start displaying the camera preview.
                                mPreviewRequest = mPreviewRequestBuilder!!.build()
                                mCaptureSession!!.setRepeatingRequest(mPreviewRequest!!, mCaptureCallback, mBackgroundHandler)
                            } catch (e: CameraAccessException) {
                                e.printStackTrace()
                            }
                        }

                        override fun onConfigureFailed(
                                cameraCaptureSession: CameraCaptureSession) {
                            showToast("Failed")
                        }
                    }, null
            )
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        }
    }

    private var isTorchOn = false

    // This method is the event listener for the flashlight button
    @RequiresApi(api = Build.VERSION_CODES.M)
    fun onFlash(view: View?) {
        try {
            isTorchOn = if (isTorchOn) {
                mPreviewRequestBuilder!!.set(CaptureRequest.FLASH_MODE, CaptureRequest.FLASH_MODE_OFF)
                mCaptureSession!!.setRepeatingRequest(mPreviewRequestBuilder!!.build(), null, null)
                false
            } else {
                mPreviewRequestBuilder?.set(CaptureRequest.FLASH_MODE, CaptureRequest.FLASH_MODE_TORCH)
                mCaptureSession?.setRepeatingRequest(mPreviewRequestBuilder!!.build(), null, null)
                true
            }
        } catch (e: CameraAccessException) {
            e.printStackTrace()
        }
    }

    /**
     * Configures the necessary [Matrix] transformation to `mTextureView`.
     * This method should be called after the camera preview size is determined in
     * setUpCameraOutputs and also the size of `mTextureView` is fixed.
     *
     * @param viewWidth  The width of `mTextureView`
     * @param viewHeight The height of `mTextureView`
     */
    private fun configureTransform(viewWidth: Int, viewHeight: Int) {
        val activity: Activity? = activity
        if (null == mPreviewSize || null == activity) {
            return
        }
        val rotation = activity.windowManager.defaultDisplay.rotation
        val matrix = Matrix()
        val viewRect = RectF(0F, 0F, viewWidth.toFloat(), viewHeight.toFloat())
        val bufferRect = RectF(0F, 0F, mPreviewSize!!.height.toFloat(), mPreviewSize!!.width.toFloat())
        val centerX = viewRect.centerX()
        val centerY = viewRect.centerY()
        if (Surface.ROTATION_90 == rotation || Surface.ROTATION_270 == rotation) {
            bufferRect.offset(centerX - bufferRect.centerX(), centerY - bufferRect.centerY())
            matrix.setRectToRect(viewRect, bufferRect, Matrix.ScaleToFit.FILL)
            val scale = max(
                    viewHeight.toFloat() / mPreviewSize!!.height,
                    viewWidth.toFloat() / mPreviewSize!!.width)
            matrix.postScale(scale, scale, centerX, centerY)
            matrix.postRotate((90 * (rotation - 2)).toFloat(), centerX, centerY)
        } else if (Surface.ROTATION_180 == rotation) {
            matrix.postRotate(180f, centerX, centerY)
        }
        mTextureView.setTransform(matrix)
    }

    /**
     * Check if the flash is supported.
     */
    private fun checkFlashSupported() {
        val available = mCameraCharacteristics.get(CameraCharacteristics.FLASH_INFO_AVAILABLE)
        mFlashSupported = available ?: false
    }

    fun parseResult(result: Array<TextResult>?): String {
        var strResult = StringBuilder()
        if (result == null || result.isEmpty()) {
            return strResult.toString()
        }
        for (i in result.indices) {
            var strCurResult = "[$i] Barcode format:"
            strCurResult += if (result[i].barcodeFormat != 0) {
                result[i].barcodeFormatString
            } else {
                result[i].barcodeFormatString_2
            }
            strCurResult += """
                
                ${result[i].barcodeText}
                """.trimIndent()
            if (i == 0) strResult = StringBuilder(strCurResult) else strResult.append("\n\n").append(strCurResult)
        }
        return strResult.toString()
    }

    fun saveYuvDataToLocalFile(data: ByteArray?, width: Int, height: Int) {
        var output: FileOutputStream? = null
        try {
            val yuvimage = YuvImage(data, ImageFormat.NV21, width, height, null)
            val baos = ByteArrayOutputStream()
            yuvimage.compressToJpeg(Rect(0, 0, width, height), 80, baos)
            val bmp = BitmapFactory.decodeByteArray(baos.toByteArray(), 0, baos.toByteArray().size)
            val mFile = File(getPictureFilePath(Objects.requireNonNull(activity)!!))
            output = FileOutputStream(mFile)
            bmp.compress(Bitmap.CompressFormat.JPEG, 85, output)
            output.write(baos.toByteArray())
        } catch (e: IOException) {
            e.printStackTrace()
        } finally {
            if (null != output) {
                try {
                    output.close()
                } catch (e: IOException) {
                    e.printStackTrace()
                }
            }
        }
    }

    private fun getPictureFilePath(context: Context): String {
        val dir = context.getExternalFilesDir(null)
        return ((if (dir == null) "" else dir.absolutePath + "/")
                + System.currentTimeMillis() + ".jpg")
    }

    /**
     * Compares two `Size`s based on their areas.
     */
    internal class CompareSizesByArea : Comparator<Size> {
        override fun compare(lhs: Size, rhs: Size): Int {
            // We cast here to ensure the multiplications won't overflow
            return java.lang.Long.signum(lhs.width.toLong() * lhs.height -
                    rhs.width.toLong() * rhs.height)
        }
    }

    /**
     * Shows an error message dialog.
     */
    class ErrorDialog : DialogFragment() {
        override fun onCreateDialog(savedInstanceState: Bundle?): Dialog {
            val activity: Activity? = activity
            return AlertDialog.Builder(activity)
                    .setMessage(arguments!!.getString(ARG_MESSAGE))
                    .setPositiveButton(android.R.string.ok) { dialogInterface, i -> activity!!.finish() }
                    .create()
        }

        companion object {
            private const val ARG_MESSAGE = "message"
            fun newInstance(message: String?): ErrorDialog {
                val dialog = ErrorDialog()
                val args = Bundle()
                args.putString(ARG_MESSAGE, message)
                dialog.arguments = args
                return dialog
            }
        }
    }

    /**
     * Shows OK/Cancel confirmation dialog about camera permission.
     */
    class ConfirmationDialog : DialogFragment() {
        override fun onCreateDialog(savedInstanceState: Bundle?): Dialog {
            val parent = parentFragment
            return AlertDialog.Builder(activity)
                    .setMessage(R.string.request_permission)
                    .setPositiveButton(android.R.string.ok) { dialog, which ->
                        parent!!.requestPermissions(arrayOf(Manifest.permission.CAMERA),
                                REQUEST_CAMERA_PERMISSION)
                    }
                    .setNegativeButton(android.R.string.cancel
                    ) { dialog, which ->
                        val activity: Activity? = parent!!.activity
                        activity?.finish()
                    }
                    .create()
        }
    }

    private class ImageData(var mBytes: ByteArray, val mWidth: Int, val mHeight: Int, val mStride: Int)

    private class MyHandler(private val textView: TextView): Handler() {
        override fun handleMessage(msg: Message) {
            super.handleMessage(msg)
            when (msg.what) {
                0x02 -> textView.text = msg.obj as String
            }
        }
    }

    companion object {
        /**
         * Conversion from screen rotation to JPEG orientation.
         */
        private val ORIENTATIONS = SparseIntArray()
        private const val REQUEST_CAMERA_PERMISSION = 1
        private const val FRAGMENT_DIALOG = "dialog"

        /**
         * Tag for the [Log].
         */
        private const val TAG = "Camera2BasicFragment"

        /**
         * Max preview width that is guaranteed by Camera2 API
         */
        private const val MAX_PREVIEW_WIDTH = 1920

        /**
         * Max preview height that is guaranteed by Camera2 API
         */
        private const val MAX_PREVIEW_HEIGHT = 1080
        var bDecoding = false

        /**
         * Given `choices` of `Size`s supported by a camera, choose the smallest one that
         * is at least as large as the respective texture view size, and that is at most as large as the
         * respective max size, and whose aspect ratio matches with the specified value. If such size
         * doesn't exist, choose the largest one that is at most as large as the respective max size,
         * and whose aspect ratio matches with the specified value.
         *
         * @param choices           The list of sizes that the camera supports for the intended output class
         * @param textureViewWidth  The width of the texture view relative to sensor coordinate
         * @param textureViewHeight The height of the texture view relative to sensor coordinate
         * @param maxWidth          The maximum width that can be chosen
         * @param maxHeight         The maximum height that can be chosen
         * @param aspectRatio       The aspect ratio
         * @return The optimal `Size`, or an arbitrary one if none were big enough
         */
        private fun chooseOptimalSize(choices: Array<Size>, textureViewWidth: Int, textureViewHeight: Int, maxWidth: Int, maxHeight: Int, aspectRatio: Size?): Size {
            // Collect the supported resolutions that are at least as big as the preview Surface
            val bigEnough: MutableList<Size> = ArrayList()
            // Collect the supported resolutions that are smaller than the preview Surface
            val notBigEnough: MutableList<Size> = ArrayList()
            val w = aspectRatio!!.width
            val h = aspectRatio.height
            for (option in choices) {
                if (option.width <= maxWidth && option.height <= maxHeight && option.height == option.width * h / w) {
                    if (option.width >= textureViewWidth && option.height >= textureViewHeight) {
                        bigEnough.add(option)
                    } else {
                        notBigEnough.add(option)
                    }
                }
            }

            // Pick the smallest of those big enough. If there is no one big enough, pick the
            // largest of those not big enough.
            return when {
                bigEnough.size > 0 -> Collections.min(bigEnough, CompareSizesByArea())
                notBigEnough.size > 0 -> Collections.max(notBigEnough, CompareSizesByArea())
                else -> {
                    Log.e(TAG, "Couldn't find any suitable preview size")
                    choices[0]
                }
            }
        }

        fun newInstance(): Camera2BasicFragment {
            return Camera2BasicFragment()
        }

        init {
            ORIENTATIONS.append(Surface.ROTATION_0, 90)
            ORIENTATIONS.append(Surface.ROTATION_90, 0)
            ORIENTATIONS.append(Surface.ROTATION_180, 270)
            ORIENTATIONS.append(Surface.ROTATION_270, 180)
        }
    }
}